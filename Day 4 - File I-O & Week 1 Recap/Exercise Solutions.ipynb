{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88367268",
   "metadata": {},
   "source": [
    "# Exercise Solutions - Day 4\n",
    "*August 1, 2024*\n",
    "\n",
    "*I School Python Bootcamp*\n",
    "\n",
    "*Author: Lauren Chambers<br>Modified from exercises by George McIntire, Hellina Nigatu, & Kat Tian*\n",
    "\n",
    "## Lab 4A - File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829caf8-fab6-4362-8e09-376c88081a09",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "*Reading and writing text files*\n",
    "\n",
    "Open up and load in `zen_of_python.txt` reverse the order of the words in it and then save the result to a new file called `zen_of_python_reversed.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "103545b3-0676-4027-b75b-b61d83724cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"zen_of_python.txt\"\n",
    "\n",
    "with open(filepath, \"r\") as f:\n",
    "    zen = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e95551ee-7094-4de4-bb3d-0d5d8b1cac85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"those of more do let's -- idea great honking one are Namespaces\",\n",
       " 'idea good a be may it explain, to easy is implementation the If',\n",
       " \"idea bad a it's explain, to hard is implementation the If\",\n",
       " 'now *right* than better often is never Although',\n",
       " 'never than better is Now',\n",
       " \"Dutch you're unless first at obvious be not may way that Although\",\n",
       " 'it do to way --obvious one only preferably and one-- be should There',\n",
       " 'guess to temptation the refuse ambiguity, of face the In',\n",
       " 'silenced explicitly Unless',\n",
       " 'silently pass never should Errors',\n",
       " 'purity beats practicality Although',\n",
       " \"rules the break to enough special aren't cases Special\",\n",
       " 'counts Readability',\n",
       " 'dense than better is Sparse',\n",
       " 'nested than better is Flat',\n",
       " 'complicated than better is Complex',\n",
       " 'complex than better is Simple',\n",
       " 'implicit than better is Explicit',\n",
       " 'ugly than better is Beautiful']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_zen = []\n",
    "for line in zen[::-1]:\n",
    "    words = line.split()\n",
    "    rev_words = words[::-1]\n",
    "    rev_line = \" \".join(rev_words)\n",
    "    rev_line = rev_line.replace(\"!\", \"\").replace(\".\", \"\")\n",
    "    rev_zen.append(rev_line)\n",
    "\n",
    "# Remove punctuation\n",
    "rev_zen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40c51768-cfab-4acf-aa17-913fbec9a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"zen_of_python_reversed.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(rev_zen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9180525b-6b1a-4a41-99f1-835134b4c41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab 4A - Working with Files.ipynb page_visits.json\n",
      "Lab 4B - Week 1 Recap.ipynb       text.txt\n",
      "README.md                         zen_of_python.txt\n",
      "case_urls.txt                     zen_of_python_reversed.txt\n",
      "countries.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda89376-f892-4054-a07e-1c3dda386ed1",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "*Reading and analyzing JSON data*\n",
    "\n",
    "Load in the `page_visits.json` file. Iterate over it and extract all the values associated with the `title` only if the `completed` value is True into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "219ce1fe-3867-430b-bf06-4267489ccf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"page_visits.json\", \"r\") as fo:\n",
    "    data = fo.read()\n",
    "    json_dicts = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1727b10-9a18-4847-ac66-92c32a78a556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['et porro tempora',\n",
       " 'quo adipisci enim quam ut ab',\n",
       " 'illo est ratione doloremque quia maiores aut',\n",
       " 'vero rerum temporibus dolor',\n",
       " 'ipsa repellendus fugit nisi',\n",
       " 'repellendus sunt dolores architecto voluptatum',\n",
       " 'ab voluptatum amet voluptas',\n",
       " 'accusamus eos facilis sint et aut voluptatem',\n",
       " 'quo laboriosam deleniti aut qui',\n",
       " 'molestiae ipsa aut voluptatibus pariatur dolor nihil',\n",
       " 'ullam nobis libero sapiente ad optio sint',\n",
       " 'distinctio vitae autem nihil ut molestias quo',\n",
       " 'voluptas quo tenetur perspiciatis explicabo natus',\n",
       " 'aliquam aut quasi',\n",
       " 'veritatis pariatur delectus',\n",
       " 'nemo perspiciatis repellat ut dolor libero commodi blanditiis omnis',\n",
       " 'repellendus veritatis molestias dicta incidunt',\n",
       " 'excepturi deleniti adipisci voluptatem et neque optio illum ad',\n",
       " 'totam atque quo nesciunt',\n",
       " 'tempore ut sint quis recusandae',\n",
       " 'cum debitis quis accusamus doloremque ipsa natus sapiente omnis',\n",
       " 'cupiditate necessitatibus ullam aut quis dolor voluptate',\n",
       " 'quis et est ut voluptate quam dolor',\n",
       " 'voluptatum omnis minima qui occaecati provident nulla voluptatem ratione',\n",
       " 'deleniti ea temporibus enim',\n",
       " 'et sequi qui architecto ut adipisci',\n",
       " 'odit optio omnis qui sunt',\n",
       " 'doloremque aut dolores quidem fuga qui nulla',\n",
       " 'sint amet quia totam corporis qui exercitationem commodi',\n",
       " 'sequi dolorem sed',\n",
       " 'eum ipsa maxime ut',\n",
       " 'tempore molestias dolores rerum sequi voluptates ipsum consequatur',\n",
       " 'suscipit qui totam',\n",
       " 'quidem at rerum quis ex aut sit quam',\n",
       " 'et quia ad iste a',\n",
       " 'incidunt ut saepe autem',\n",
       " 'laudantium quae eligendi consequatur quia et vero autem',\n",
       " 'sequi ut omnis et',\n",
       " 'molestiae nisi accusantium tenetur dolorem et',\n",
       " 'nulla quis consequatur saepe qui id expedita',\n",
       " 'in omnis laboriosam',\n",
       " 'odio iure consequatur molestiae quibusdam necessitatibus quia sint',\n",
       " 'vel nihil et molestiae iusto assumenda nemo quo ut',\n",
       " 'debitis accusantium ut quo facilis nihil quis sapiente necessitatibus',\n",
       " 'totam quia dolorem et illum repellat voluptas optio',\n",
       " 'ad illo quis voluptatem temporibus',\n",
       " 'a eos eaque nihil et exercitationem incidunt delectus',\n",
       " 'autem temporibus harum quisquam in culpa',\n",
       " 'aut aut ea corporis',\n",
       " 'ipsa dolores vel facilis ut',\n",
       " 'inventore aut nihil minima laudantium hic qui omnis',\n",
       " 'provident aut nobis culpa',\n",
       " 'ut asperiores perspiciatis veniam ipsum rerum saepe',\n",
       " 'voluptatem libero consectetur rerum ut',\n",
       " 'nulla aliquid eveniet harum laborum libero alias ut unde',\n",
       " 'qui molestiae voluptatibus velit iure harum quisquam',\n",
       " 'et labore eos enim rerum consequatur sunt',\n",
       " 'placeat minima consequatur rem qui ut',\n",
       " 'aut consectetur in blanditiis deserunt quia sed laboriosam',\n",
       " 'explicabo consectetur debitis voluptates quas quae culpa rerum non',\n",
       " 'maiores accusantium architecto necessitatibus reiciendis ea aut',\n",
       " 'molestiae suscipit ratione nihil odio libero impedit vero totam',\n",
       " 'eum itaque quod reprehenderit et facilis dolor autem ut',\n",
       " 'accusamus adipisci dicta qui quo ea explicabo sed vero',\n",
       " 'rerum non ex sapiente',\n",
       " 'voluptatem nobis consequatur et assumenda magnam',\n",
       " 'nam quia quia nulla repellat assumenda quibusdam sit nobis',\n",
       " 'dolorem veniam quisquam deserunt repellendus',\n",
       " 'debitis vitae delectus et harum accusamus aut deleniti a',\n",
       " 'debitis adipisci quibusdam aliquam sed dolore ea praesentium nobis',\n",
       " 'ex hic consequuntur earum omnis alias ut occaecati culpa',\n",
       " 'omnis laboriosam molestias animi sunt dolore',\n",
       " 'ea odio perferendis officiis',\n",
       " 'fugiat aut voluptatibus corrupti deleniti velit iste odio',\n",
       " 'laudantium eius officia perferendis provident perspiciatis asperiores',\n",
       " 'nesciunt itaque commodi tempore',\n",
       " 'omnis consequuntur cupiditate impedit itaque ipsam quo',\n",
       " 'debitis nisi et dolorem repellat et',\n",
       " 'inventore saepe cumque et aut illum enim',\n",
       " 'omnis nulla eum aliquam distinctio',\n",
       " 'vel non beatae est',\n",
       " 'culpa eius et voluptatem et',\n",
       " 'accusamus sint iusto et voluptatem exercitationem',\n",
       " 'temporibus atque distinctio omnis eius impedit tempore molestias pariatur',\n",
       " 'rerum debitis voluptatem qui eveniet tempora distinctio a',\n",
       " 'rerum ex veniam mollitia voluptatibus pariatur',\n",
       " 'consequuntur aut ut fugit similique',\n",
       " 'dignissimos quo nobis earum saepe',\n",
       " 'quis eius est sint explicabo',\n",
       " 'numquam repellendus a magnam']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_titles = []\n",
    "\n",
    "for visit in json_dicts:\n",
    "    if visit['completed'] == True:\n",
    "        completed_titles.append(visit[\"title\"])\n",
    "\n",
    "completed_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe806c-cd2b-4283-80ee-84ec0af0b3d1",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "*Reading and analyzing tabular data*\n",
    "\n",
    "Load the `countries.csv` file (you can use `csv` or `pandas`, whichever you prefer). Calculate the average life expectancy for each continent in 1952.\n",
    "\n",
    "#### Use `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1bb8fd-3cda-4933-b204-2c47c10e2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5066d62-117b-48cb-83e8-870083960c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = pd.read_csv(\"countries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82e832e8-bb66-4dcd-9ad3-e4e1492dd923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_l/m1t5fd6s2yn3409p5pl_8q7c0000gn/T/ipykernel_16545/3873535045.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n",
      "/var/folders/_l/m1t5fd6s2yn3409p5pl_8q7c0000gn/T/ipykernel_16545/3873535045.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n",
      "/var/folders/_l/m1t5fd6s2yn3409p5pl_8q7c0000gn/T/ipykernel_16545/3873535045.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n",
      "/var/folders/_l/m1t5fd6s2yn3409p5pl_8q7c0000gn/T/ipykernel_16545/3873535045.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n",
      "/var/folders/_l/m1t5fd6s2yn3409p5pl_8q7c0000gn/T/ipykernel_16545/3873535045.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Americas': 53.27983999999999,\n",
       " 'Asia': 46.31439393939394,\n",
       " 'Africa': 39.13549999999999,\n",
       " 'Oceania': 69.255,\n",
       " 'Europe': 64.40849999999999}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents = set(countries_df.continent)\n",
    "\n",
    "life_per_cont = {}\n",
    "for c in continents:\n",
    "    lifeExp = countries_df[countries_df.continent == c][countries_df.year == 1952].lifeExp.mean()\n",
    "    life_per_cont[c] = lifeExp\n",
    "\n",
    "life_per_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fd2e2-0515-44a1-b9a1-89ee74bef268",
   "metadata": {},
   "source": [
    "#### Use `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ebca93-5c57-42b7-9e2f-c4762e5b65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b024412-f42f-4eef-b0ce-dda7709af627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'year', 'pop', 'continent', 'lifeExp', 'gdpPercap']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_data = []\n",
    "\n",
    "with open('countries.csv', newline='') as file_object:\n",
    "    reader = csv.reader(file_object)\n",
    "    for row in reader:\n",
    "        countries_data.append(row)\n",
    "\n",
    "countries_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a78e34d-ec08-4daf-ac81-09b8c09e5c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Africa', 'Americas', 'Asia', 'Europe', 'Oceania'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continents = set([row[3] for row in countries_data[1:]])\n",
    "continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f1e437a-8fab-4ff8-801e-fccc85bab4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Europe': 64.40849999999999,\n",
       " 'Americas': 53.279839999999986,\n",
       " 'Africa': 39.13549999999999,\n",
       " 'Asia': 46.31439393939394,\n",
       " 'Oceania': 69.255}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "life_per_cont = {}\n",
    "\n",
    "for c in continents:\n",
    "    lifeExps = []\n",
    "    for row in countries_data[::-1]: \n",
    "        year = row[1]\n",
    "        lifeExp = row[4]\n",
    "        cont = row[3]\n",
    "        if cont == c and year == \"1952\":\n",
    "            lifeExps.append(float(lifeExp))\n",
    "\n",
    "    life_per_cont[c] = sum(lifeExps) / len(lifeExps)\n",
    "\n",
    "life_per_cont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f2e3a-505f-4c11-9ed3-31df3045760a",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "*Self-teaching skills using package documentation*\n",
    "\n",
    "Load `countries.csv` into a pandas dataframe.\n",
    "\n",
    "Review this tutorial on the `pandas` website: https://pandas.pydata.org/docs/getting_started/intro_tutorials/05_add_columns.html\n",
    "\n",
    "Use it to figure out how to add a new column to the dataframe: the raw GDP, as opposed to the per capita. (`gdp = pop * gdpPercap`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46493a35-a30d-421f-b32e-c63b0d9fd8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>pop</th>\n",
       "      <th>continent</th>\n",
       "      <th>lifeExp</th>\n",
       "      <th>gdpPercap</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>8425333.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>28.801</td>\n",
       "      <td>779.445314</td>\n",
       "      <td>6.567086e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1957</td>\n",
       "      <td>9240934.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>30.332</td>\n",
       "      <td>820.853030</td>\n",
       "      <td>7.585449e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1962</td>\n",
       "      <td>10267083.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>31.997</td>\n",
       "      <td>853.100710</td>\n",
       "      <td>8.758856e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1967</td>\n",
       "      <td>11537966.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>34.020</td>\n",
       "      <td>836.197138</td>\n",
       "      <td>9.648014e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1972</td>\n",
       "      <td>13079460.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>36.088</td>\n",
       "      <td>739.981106</td>\n",
       "      <td>9.678553e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1987</td>\n",
       "      <td>9216418.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>62.351</td>\n",
       "      <td>706.157306</td>\n",
       "      <td>6.508241e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1992</td>\n",
       "      <td>10704340.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>60.377</td>\n",
       "      <td>693.420786</td>\n",
       "      <td>7.422612e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>1997</td>\n",
       "      <td>11404948.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>46.809</td>\n",
       "      <td>792.449960</td>\n",
       "      <td>9.037851e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2002</td>\n",
       "      <td>11926563.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>39.989</td>\n",
       "      <td>672.038623</td>\n",
       "      <td>8.015111e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "      <td>5.782658e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1704 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  year         pop continent  lifeExp   gdpPercap  \\\n",
       "0     Afghanistan  1952   8425333.0      Asia   28.801  779.445314   \n",
       "1     Afghanistan  1957   9240934.0      Asia   30.332  820.853030   \n",
       "2     Afghanistan  1962  10267083.0      Asia   31.997  853.100710   \n",
       "3     Afghanistan  1967  11537966.0      Asia   34.020  836.197138   \n",
       "4     Afghanistan  1972  13079460.0      Asia   36.088  739.981106   \n",
       "...           ...   ...         ...       ...      ...         ...   \n",
       "1699     Zimbabwe  1987   9216418.0    Africa   62.351  706.157306   \n",
       "1700     Zimbabwe  1992  10704340.0    Africa   60.377  693.420786   \n",
       "1701     Zimbabwe  1997  11404948.0    Africa   46.809  792.449960   \n",
       "1702     Zimbabwe  2002  11926563.0    Africa   39.989  672.038623   \n",
       "1703     Zimbabwe  2007  12311143.0    Africa   43.487  469.709298   \n",
       "\n",
       "               gdp  \n",
       "0     6.567086e+09  \n",
       "1     7.585449e+09  \n",
       "2     8.758856e+09  \n",
       "3     9.648014e+09  \n",
       "4     9.678553e+09  \n",
       "...            ...  \n",
       "1699  6.508241e+09  \n",
       "1700  7.422612e+09  \n",
       "1701  9.037851e+09  \n",
       "1702  8.015111e+09  \n",
       "1703  5.782658e+09  \n",
       "\n",
       "[1704 rows x 7 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_df = pd.read_csv(\"countries.csv\")\n",
    "\n",
    "countries_df[\"gdp\"] = countries_df[\"pop\"] * countries_df[\"gdpPercap\"]\n",
    "\n",
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb6ddf-ec75-43b5-bcd2-952719821b00",
   "metadata": {},
   "source": [
    "## Lab 4B - Week 1 Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abf479-6e5a-4a63-a693-665e9858fb25",
   "metadata": {},
   "source": [
    "### Exercise  1\n",
    "\n",
    "Create a dictionary where the ids in case_ids are keys in dictionary where the values are the urls for their legal cases. Put the case id in the curly brackets in the url string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f2a40a-e873-470f-b497-8ef2417a8ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://scholar.google.com/scholar_case?case={}\"\n",
    "case_ids = [6768454, 7712102, 6448738, 5374866, 6167299, 4683704, 3160303,\n",
    "       3379031, 5507176, 7024792, 9332965, 3999836, 1314612, 5918388,\n",
    "       1994897, 6497745, 4011633, 2837473, 7121246, 2001872]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef8415c9-1f6a-49c3-a28a-8c14efdbedef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6768454: 'https://scholar.google.com/scholar_case?case=6768454',\n",
       " 7712102: 'https://scholar.google.com/scholar_case?case=7712102',\n",
       " 6448738: 'https://scholar.google.com/scholar_case?case=6448738',\n",
       " 5374866: 'https://scholar.google.com/scholar_case?case=5374866',\n",
       " 6167299: 'https://scholar.google.com/scholar_case?case=6167299',\n",
       " 4683704: 'https://scholar.google.com/scholar_case?case=4683704',\n",
       " 3160303: 'https://scholar.google.com/scholar_case?case=3160303',\n",
       " 3379031: 'https://scholar.google.com/scholar_case?case=3379031',\n",
       " 5507176: 'https://scholar.google.com/scholar_case?case=5507176',\n",
       " 7024792: 'https://scholar.google.com/scholar_case?case=7024792',\n",
       " 9332965: 'https://scholar.google.com/scholar_case?case=9332965',\n",
       " 3999836: 'https://scholar.google.com/scholar_case?case=3999836',\n",
       " 1314612: 'https://scholar.google.com/scholar_case?case=1314612',\n",
       " 5918388: 'https://scholar.google.com/scholar_case?case=5918388',\n",
       " 1994897: 'https://scholar.google.com/scholar_case?case=1994897',\n",
       " 6497745: 'https://scholar.google.com/scholar_case?case=6497745',\n",
       " 4011633: 'https://scholar.google.com/scholar_case?case=4011633',\n",
       " 2837473: 'https://scholar.google.com/scholar_case?case=2837473',\n",
       " 7121246: 'https://scholar.google.com/scholar_case?case=7121246',\n",
       " 2001872: 'https://scholar.google.com/scholar_case?case=2001872'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_dict = {}\n",
    "\n",
    "for id in case_ids:\n",
    "    cases_dict[id] = url.format(id)\n",
    "\n",
    "cases_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611784dc-ad18-4730-9c16-0895d370609c",
   "metadata": {},
   "source": [
    "### Exercise  2\n",
    "\n",
    "Use python to demonstrate which sentence contains more unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d559f928-ff86-43ad-b07e-88a63ec29a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"\"\"Data from the CDC’s National \n",
    "Health and Nutrition Examination Survey shows that America's drinking habits are changing.\n",
    "Sure, water is still our most consumed beverage, accounting for nearly half of our total consumption.\"\"\"\n",
    "\n",
    "sentence2 = \"\"\" But consumption of other beverages, like soft drinks and regular milk, \n",
    "are way down across all age groups. It’s a fascinating look into how Americans \n",
    "have replaced soda with bottled water.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25d9e1c-6dba-4a89-b42d-6d16eb03b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 31\n"
     ]
    }
   ],
   "source": [
    "n_words1 = len(set(sentence1.split()))\n",
    "n_words2 = len(set(sentence2.split()))\n",
    "print(n_words1, n_words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f34e2-3ebf-442a-957b-2d85d3c42d20",
   "metadata": {},
   "source": [
    "### Exercise  3\n",
    "\n",
    "Use list comprehensions to demonstrate which sentence from Exercise 2 contains more long words - words 7 letters or longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20c1fb2c-91b1-4820-9596-0d13c65be563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: 10\n",
      "Sentence 2: 8\n"
     ]
    }
   ],
   "source": [
    "n_long_words1 = len([word for word in sentence1.split() if len(word) >= 7])\n",
    "n_long_words2 = len([word for word in sentence2.split() if len(word) >= 7])\n",
    "print(\"Sentence 1:\", n_long_words1)\n",
    "print(\"Sentence 2:\", n_long_words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7232b8ac-02bf-44a5-81fa-12d9303c14ce",
   "metadata": {},
   "source": [
    "### Exercise  4\n",
    "*First Letter Frequency*\n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Create a dictionary that keeps track of the frequencies of the first letters of the words in the following passage.\n",
    "\n",
    "Casing does not matter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d717cd-83de-4f11-8d7f-acc25ce6ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"MLPs – the other core building block of Transformers – also introduce an efficiency bottleneck, \n",
    "which becomes more acute as we continue to optimize attention. \n",
    "MLPs are quadratic in the model width, which means they grow more expensive as you make models wider. \n",
    "This is why models like GPT-3 are so expensive, \n",
    "and why GPT-4 has allegedly started using techniques like mixtures of experts.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37fc6e6f-62f1-40f5-b2cf-849c8158fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 10,\n",
       " 't': 7,\n",
       " 'o': 4,\n",
       " 'c': 2,\n",
       " 'b': 4,\n",
       " 'a': 10,\n",
       " 'i': 3,\n",
       " 'e': 4,\n",
       " 'w': 7,\n",
       " 'q': 1,\n",
       " 'g': 3,\n",
       " 'y': 1,\n",
       " 'l': 2,\n",
       " 's': 2,\n",
       " 'h': 1,\n",
       " 'u': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_letters = {}\n",
    "\n",
    "for word in text.split():\n",
    "    first_letter = word.lower()[0]\n",
    "\n",
    "    if first_letter.isalpha():\n",
    "\n",
    "        if first_letter not in first_letters.keys():\n",
    "            first_letters[first_letter] = 0\n",
    "    \n",
    "        first_letters[first_letter] += 1\n",
    "\n",
    "first_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcd9a35d-5e70-422c-89c7-ea1b17443ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m': 8,\n",
       " '–': 2,\n",
       " 't': 5,\n",
       " 'o': 4,\n",
       " 'c': 2,\n",
       " 'b': 4,\n",
       " 'a': 10,\n",
       " 'i': 3,\n",
       " 'e': 4,\n",
       " 'w': 7,\n",
       " 'q': 1,\n",
       " 'g': 1,\n",
       " 'y': 1,\n",
       " 'l': 2,\n",
       " 's': 2,\n",
       " 'h': 1,\n",
       " 'u': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Credit to Vijay for this dict comprehension answer!\n",
    "first_letters = [word[0] for word in text.split()]\n",
    "{k.lower(): first_letters.count(k.lower()) for k in first_letters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38669415-36be-4903-ae54-66641e52b4a4",
   "metadata": {},
   "source": [
    "**Part 2**\n",
    "\n",
    "Create a new dictionary that tallies the frequencies of starting letters that are vowel and consonants.\n",
    "\n",
    "Do this by iterating over the letter frequency dictionary you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fa2fdca-88fc-4c1f-bbcc-a9b6aa779eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vowels': 22, 'consonants': 40}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels_v_consonants = {\"vowels\": 0,\n",
    "                       \"consonants\": 0}\n",
    "\n",
    "for key, value in first_letters.items():\n",
    "    if key in \"aeiou\":\n",
    "        vowels_v_consonants[\"vowels\"] += value\n",
    "    else:\n",
    "        vowels_v_consonants[\"consonants\"] += value\n",
    "\n",
    "vowels_v_consonants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9af57",
   "metadata": {},
   "source": [
    "### Exercise  5 \n",
    "*Sorting and flattening*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4961393",
   "metadata": {},
   "source": [
    "Write a function that collects all the numbers in a list of lists into one list and sorts them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8935a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_list= [[2,3], [9,2,51,6],[9,1,22,44,12],[0]] # Demonstrate with this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f9f2c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 2, 3, 6, 9, 9, 12, 22, 44, 51]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_and_flatten(list_of_lists):\n",
    "    one_list = []\n",
    "    for l in list_of_lists:\n",
    "        one_list += l\n",
    "\n",
    "    return sorted(one_list)\n",
    "\n",
    "sort_and_flatten(nested_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070d34d",
   "metadata": {},
   "source": [
    "### Exercise  6\n",
    "*String replacement*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b3059",
   "metadata": {},
   "source": [
    "For each word in a sentence replace a with @, s with $, o with 0, l with !.\n",
    "\n",
    "But do not touch a letter if its the first character in a word.\n",
    "\n",
    "For example, analysis => `an@!y$i$`  We do not touch the first a.\n",
    "\n",
    "Hint: use `.split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e297f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Instead, your cover letter should go beyond your work history to\n",
    "talk about things that make you especially well-suited for the job.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0c93435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In$te@d, y0ur c0ver letter sh0u!d g0 bey0nd y0ur w0rk hi$t0ry t0 t@!k ab0ut thing$ th@t m@ke y0u e$peci@!!y we!!-$uited f0r the j0b. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = \"\"\n",
    "for word in text.split():\n",
    "    new_word = word[0]\n",
    "    for letter in word[1:]:\n",
    "        if letter == \"a\":\n",
    "            new_word += \"@\"\n",
    "        elif letter == \"s\":\n",
    "            new_word += \"$\"\n",
    "        elif letter == \"o\":\n",
    "            new_word += \"0\"\n",
    "        elif letter == \"l\":\n",
    "            new_word += \"!\"\n",
    "        else:\n",
    "            new_word += letter\n",
    "    new_text += new_word + \" \"\n",
    "\n",
    "new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9f0d1",
   "metadata": {},
   "source": [
    "### Exercise  7\n",
    "\n",
    "Create combination pairs for every name in a list\n",
    "\n",
    "Expected output:\n",
    "\n",
    "```python\n",
    "[('Andrea', 'Bob'),\n",
    " ('Andrea', 'Cassandra'),\n",
    " ('Andrea', 'Doug'),\n",
    " ('Bob', 'Cassandra'),\n",
    " ('Bob', 'Doug'),\n",
    " ('Cassandra', 'Doug')]\n",
    " ```\n",
    "\n",
    " Bonus points if you use a list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2998d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Andrea', 'Bob', 'Cassandra', 'Doug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "158d5da7-d455-408a-a91d-7f6ba2411721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andrea', 'Bob'),\n",
       " ('Andrea', 'Cassandra'),\n",
       " ('Andrea', 'Doug'),\n",
       " ('Bob', 'Cassandra'),\n",
       " ('Bob', 'Doug'),\n",
       " ('Cassandra', 'Doug')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With for loop\n",
    "combos = []\n",
    "for i in range(len(names)):\n",
    "    n1 = names[i]\n",
    "    for n2 in names[i:]:\n",
    "        if n1 != n2:\n",
    "            combos.append((n1, n2))\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a7e27d7-1df5-47c3-b9a2-845b757d1e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Andrea', 'Bob'),\n",
       " ('Andrea', 'Cassandra'),\n",
       " ('Andrea', 'Doug'),\n",
       " ('Bob', 'Cassandra'),\n",
       " ('Bob', 'Doug'),\n",
       " ('Cassandra', 'Doug')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With list comprehension\n",
    "combos = [(names[i], n2) for i in range(len(names)) for n2 in names[i:] if names[i] != n2]\n",
    "combos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf02ffb3",
   "metadata": {},
   "source": [
    "### Exercise  8\n",
    "\n",
    "Write a function to extract the name located between the parentheses in texts.\n",
    "\n",
    "Include a kwarg, `lowercase`, that outputs the name in all lowercase letters if True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98a26288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with these\n",
    "txt1 = \"While walking in the park, (Emily) found a mysterious old key.\"\n",
    "txt2 = \"After buying the lottery ticket, (David) couldn't believe his luck when he won.\"\n",
    "txt3 = \"For the school bake sale, (Sarah) baked some delicious chocolate chip cookies.\"\n",
    "txt4 = \"On an exciting adventure to the mountains, (Michael) and his friends went.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcd6fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(text, lowercase=True):\n",
    "    name = text.split(\"(\")[-1]\n",
    "    name = name.split(\")\")[0]\n",
    "\n",
    "    if lowercase:\n",
    "        name = name.lower()\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6417eb7-9879-4c78-afc7-3670a0d01df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emily'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85afad38-bd80-4fb8-b5b4-531b3d8cc99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(txt2, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db1c0359-7f0a-41e8-87e1-bc0f0fe93a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sarah'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a6e01d-c579-49e6-bd2e-2bb754ee705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_name(txt4, lowercase=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17a45",
   "metadata": {},
   "source": [
    "### Exercise  9\n",
    "\n",
    "Calculate the euclidean and manhattan distances between these pair of numerical lists. Use functions from the `math` package if helpful.\n",
    "\n",
    "Hint: use the `abs` function for manhattan distance\n",
    "\n",
    "[Euclidean distance formula](https://www.cuemath.com/euclidean-distance-formula/)\n",
    "\n",
    "\n",
    "[Manhattan distance formula](https://xlinux.nist.gov/dads/HTML/manhattanDistance.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e973d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "numlist1 = [1,6,8]\n",
    "numlist2 = [5,1,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a283d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.708203932499369"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist = 0\n",
    "\n",
    "for i,j in zip(numlist1, numlist2):\n",
    "    euclidean_dist += (i-j)**2\n",
    "    \n",
    "euclidean_dist**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "619e6102-a1be-4e9d-a297-0fce426de5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan_dist = 0\n",
    "\n",
    "for i,j in zip(numlist1, numlist2):\n",
    "    manhattan_dist += abs(i-j)\n",
    "manhattan_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963cf130-8640-46c5-b690-76006232af4b",
   "metadata": {},
   "source": [
    "# Exercise 10\n",
    "\n",
    "Given a dictionary of student names and their scores, create a new dictionary denoting whether they passed or failed. The list should say \"PASS\" for students who scored 80 or above, and \"FAIL\" for students who scored below 80. Use a dictionary comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73bce156-fd4d-42bd-acf9-32c9dc6b9870",
   "metadata": {},
   "outputs": [],
   "source": [
    "students_scores = {\n",
    "    'Marietta': 85,\n",
    "    'Peter': 60,\n",
    "    'Cedric': 75,\n",
    "    'Julia': 90,\n",
    "    'Rhiya': 55\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a0e0bd1-1f06-4f79-9929-2f51b4c886b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Marietta': 'PASS',\n",
       " 'Peter': 'FAIL',\n",
       " 'Cedric': 'FAIL',\n",
       " 'Julia': 'PASS',\n",
       " 'Rhiya': 'FAIL'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_fail = {student: \"PASS\" if score >= 80 else \"FAIL\" for student, score in students_scores.items()}\n",
    "pass_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036888e4-a25c-46e9-a641-fa3196c91a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
